// 1. First, modify your "Store Embeddings" node in N8N to output a JSON file:
const items = $input.all();
const embeddingsData = items.map(item => {
  const embedding = item.json?.data?.[0]?.embedding || item.json?.embedding;
  
  if (embedding) {
    return {
      embedding: embedding,
      content: item.json?.input || item.json?.content,
      chunkIndex: item.json?.chunkIndex,
      sourceUrl: item.json?.sourceUrl
    };
  }
  return null;
}).filter(item => item !== null);

// Create a JSON object to store everything
const jsonOutput = {
  websiteData: {
    embeddings: embeddingsData,
    lastUpdated: new Date().toISOString(),
    totalChunks: embeddingsData.length
  }
};

// Return this data so you can save it as a file
return [
  {
    json: {
      success: true,
      storedEmbeddingsCount: embeddingsData.length,
      lastUpdated: new Date().toISOString(),
      fileContent: jsonOutput // This is what you'll save to GitHub
    }
  }
];

// 2. After scraping your website once, save the 'fileContent' output as 'website-data.json' in your GitHub repo

// 3. Modify your Netlify proxy function to read from this file:
const fs = require('fs').promises;
const path = require('path');

// Load the static website data
const WEBSITE_DATA = require('../website-data.json');

exports.handler = async function(event, context) {
  console.log('Function started');
  
  // Set CORS headers
  const headers = {
    'Access-Control-Allow-Origin': '*',
    'Access-Control-Allow-Headers': 'Content-Type',
    'Access-Control-Allow-Methods': 'GET, POST, OPTIONS'
  };
  
  // Handle preflight OPTIONS request
  if (event.httpMethod === 'OPTIONS') {
    console.log('Handling OPTIONS request');
    return {
      statusCode: 200,
      headers
    };
  }

  try {
    let fullUrl;
    const postData = JSON.parse(event.body || '{}');
    
    if (event.path.includes('scrape')) {
      // Since we're using static data, just return success
      return {
        statusCode: 200,
        headers,
        body: JSON.stringify({ 
          success: true, 
          chunkCount: WEBSITE_DATA.websiteData.totalChunks, 
          timestamp: WEBSITE_DATA.websiteData.lastUpdated
        })
      };
    } else if (event.path.includes('query')) {
      // Build URL with embeddings included from our static file
      fullUrl = 'https://lincolnpolynia.app.n8n.cloud/webhook-test/chatbot/query';
      
      const queryParams = new URLSearchParams();
      queryParams.append('query', postData.query);
      queryParams.append('userId', postData.userId || 'anonymous');
      queryParams.append('storedEmbeddings', JSON.stringify(WEBSITE_DATA.websiteData.embeddings));
      
      fullUrl += '?' + queryParams.toString();
      
      const response = await fetch(fullUrl, {
        method: 'GET',
        headers: {
          'Accept': 'application/json'
        }
      });
      
      const data = await response.json();
      
      return {
        statusCode: 200,
        headers,
        body: JSON.stringify({
          response: data.text || data.response || "I don't have enough information to answer that question."
        })
      };
    }
    
  } catch (error) {
    console.error('Error in proxy function:', error.message);
    return {
      statusCode: 500,
      headers,
      body: JSON.stringify({ 
        error: error.message
      })
    };
  }
};

// 4. Modify your N8N "Find Relevant Content" node to accept embeddings from query params:
const items = $input.all();
let queryEmbedding, query, userId, storedEmbeddings;

// Extract data from the input
if (items.length > 0 && items[0].json) {
  const inputData = items[0].json;
  
  // Extract query embedding
  if (inputData.data && inputData.data[0]) {
    queryEmbedding = inputData.data[0].embedding;
  } else if (inputData.embedding) {
    queryEmbedding = inputData.embedding;
  }
  
  // Extract query, userId, and storedEmbeddings
  query = inputData.query || inputData.input;
  userId = inputData.userId || 'anonymous';
  
  // Parse stored embeddings from query params
  if (inputData.storedEmbeddings) {
    try {
      storedEmbeddings = JSON.parse(inputData.storedEmbeddings);
    } catch (e) {
      console.log("Error parsing stored embeddings");
      storedEmbeddings = [];
    }
  } else {
    storedEmbeddings = [];
  }
}

// Rest of your cosine similarity code continues...
