<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio to Text with ChatGPT</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
            color: #333;
        }
        .container {
            background-color: #f9f9f9;
            border-radius: 10px;
            padding: 20px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }
        h1 {
            text-align: center;
            color: #2c3e50;
        }
        .status {
            text-align: center;
            font-weight: bold;
            margin: 15px 0;
            min-height: 24px;
        }
        .recording {
            color: #e74c3c;
        }
        .controls {
            display: flex;
            justify-content: center;
            flex-wrap: wrap;
            gap: 15px;
            margin-bottom: 20px;
        }
        button {
            background-color: #3498db;
            color: white;
            border: none;
            padding: 10px 20px;
            border-radius: 5px;
            cursor: pointer;
            font-size: 16px;
            transition: background-color 0.3s;
            -webkit-appearance: none;
            -moz-appearance: none;
            appearance: none;
        }
        button:hover {
            background-color: #2980b9;
        }
        button:disabled {
            background-color: #95a5a6;
            cursor: not-allowed;
        }
        #startButton {
            background-color: #2ecc71;
        }
        #startButton:hover {
            background-color: #27ae60;
        }
        #stopButton {
            background-color: #e74c3c;
        }
        #stopButton:hover {
            background-color: #c0392b;
        }
        #resetButton {
            background-color: #95a5a6;
        }
        #resetButton:hover {
            background-color: #7f8c8d;
        }
        #processButton {
            background-color: #9b59b6;
        }
        #processButton:hover {
            background-color: #8e44ad;
        }
        .output-container {
            margin-top: 20px;
            display: flex;
            flex-direction: column;
            gap: 20px;
        }
        .output-box {
            width: 100%;
            min-height: 150px;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            font-size: 16px;
            background-color: white;
            overflow-wrap: break-word;
            word-wrap: break-word;
            word-break: break-word;
            box-sizing: border-box;
        }
        .column-header {
            font-weight: bold;
            margin-bottom: 5px;
            color: #2c3e50;
        }
        .error {
            color: #e74c3c;
            text-align: center;
            font-weight: bold;
            margin: 10px 0;
        }
        .info {
            font-size: 14px;
            color: #7f8c8d;
            margin-top: 20px;
            text-align: center;
        }
        .loading {
            text-align: center;
            margin: 10px 0;
        }
        .spinner {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 3px solid rgba(0, 0, 0, 0.1);
            border-radius: 50%;
            border-top-color: #3498db;
            animation: spin 1s ease-in-out infinite;
            margin-right: 10px;
        }
        @keyframes spin {
            to { transform: rotate(360deg); }
        }
        @media (max-width: 600px) {
            .controls {
                flex-direction: column;
                align-items: center;
            }
            button {
                width: 100%;
                max-width: 250px;
            }
        }
        .record-dot {
            display: inline-block;
            width: 12px;
            height: 12px;
            background-color: #e74c3c;
            border-radius: 50%;
            margin-right: 5px;
            animation: pulse 1.5s ease infinite;
        }
        @keyframes pulse {
            0% { transform: scale(0.8); opacity: 0.8; }
            50% { transform: scale(1.2); opacity: 1; }
            100% { transform: scale(0.8); opacity: 0.8; }
        }
        #audioVisualizer {
            width: 100%;
            height: 60px;
            background-color: #f0f0f0;
            border-radius: 5px;
            margin-top: 10px;
            position: relative;
            overflow: hidden;
        }
        .visualizer-bar {
            position: absolute;
            bottom: 0;
            background-color: #3498db;
            width: 3px;
            margin-right: 2px;
            border-radius: 2px 2px 0 0;
        }
        #audioTimer {
            text-align: center;
            font-size: 14px;
            margin-top: 5px;
            color: #7f8c8d;
        }
        #manualInput {
            width: 100%;
            margin-top: 10px;
            padding: 10px;
            border: 1px solid #ddd;
            border-radius: 5px;
            display: none;
        }
        #toggleModeButton {
            background-color: #f39c12;
            margin-top: 10px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Audio to Text with ChatGPT</h1>
        <div class="status" id="status">Ready to record</div>
        
        <div class="controls">
            <button id="startButton">Start Recording</button>
            <button id="stopButton" disabled>Stop Recording</button>
            <button id="resetButton">Clear All</button>
            <button id="processButton">Process with ChatGPT</button>
        </div>
        
        <div id="audioVisualizer"></div>
        <div id="audioTimer">00:00</div>
        
        <button id="toggleModeButton">Switch to Manual Input</button>
        <textarea id="manualInput" placeholder="Or type your text here..." rows="4"></textarea>
        
        <div class="output-container">
            <div>
                <div class="column-header">Your Speech:</div>
                <div class="output-box" id="output"></div>
            </div>
            <div>
                <div class="column-header">ChatGPT Response:</div>
                <div class="output-box" id="aiOutput"></div>
                <div id="loadingContainer" class="loading" style="display: none;">
                    <div class="spinner"></div>
                    <span>Processing with ChatGPT...</span>
                </div>
            </div>
        </div>
        <div class="info">
            <p id="recordingInfo">Click "Start Recording" and speak into your microphone. ChatGPT will transcribe and respond to your speech.</p>
            <p id="debugInfo" style="font-size: 12px; color: #999;"></p>
        </div>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const startButton = document.getElementById('startButton');
            const stopButton = document.getElementById('stopButton');
            const resetButton = document.getElementById('resetButton');
            const processButton = document.getElementById('processButton');
            const toggleModeButton = document.getElementById('toggleModeButton');
            const status = document.getElementById('status');
            const output = document.getElementById('output');
            const aiOutput = document.getElementById('aiOutput');
            const loadingContainer = document.getElementById('loadingContainer');
            const audioVisualizer = document.getElementById('audioVisualizer');
            const audioTimer = document.getElementById('audioTimer');
            const manualInput = document.getElementById('manualInput');
            const recordingInfo = document.getElementById('recordingInfo');
            const debugInfo = document.getElementById('debugInfo');
            
            let mediaRecorder;
            let audioChunks = [];
            let recordingStartTime;
            let timerInterval;
            let audioContext;
            let analyser;
            let visualizerBars = [];
            let isManualMode = false;
            
            // Debug info
            const isMobile = /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
            debugInfo.textContent = `Device: ${isMobile ? 'Mobile' : 'Desktop'}`;
            
            // Create visualizer bars
            function createVisualizer() {
                audioVisualizer.innerHTML = '';
                visualizerBars = [];
                
                const barCount = 50;
                const barWidth = audioVisualizer.clientWidth / barCount - 2;
                
                for (let i = 0; i < barCount; i++) {
                    const bar = document.createElement('div');
                    bar.className = 'visualizer-bar';
                    bar.style.left = (i * (barWidth + 2)) + 'px';
                    bar.style.width = barWidth + 'px';
                    bar.style.height = '0px';
                    audioVisualizer.appendChild(bar);
                    visualizerBars.push(bar);
                }
            }
            
            // Update timer display
            function updateTimer() {
                const now = Date.now();
                const elapsedSeconds = Math.floor((now - recordingStartTime) / 1000);
                const minutes = Math.floor(elapsedSeconds / 60).toString().padStart(2, '0');
                const seconds = (elapsedSeconds % 60).toString().padStart(2, '0');
                audioTimer.textContent = `${minutes}:${seconds}`;
            }
            
            // Update visualizer display
            function updateVisualizer(dataArray) {
                for (let i = 0; i < visualizerBars.length; i++) {
                    const value = dataArray[i * Math.floor(dataArray.length / visualizerBars.length)];
                    const height = value / 255 * audioVisualizer.clientHeight;
                    visualizerBars[i].style.height = height + 'px';
                }
            }
            
            // Start recording
            startButton.addEventListener('click', async function() {
                try {
                    // Request microphone access
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    
                    // Set up audio context for visualizer
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    const source = audioContext.createMediaStreamSource(stream);
                    analyser = audioContext.createAnalyser();
                    analyser.fftSize = 256;
                    source.connect(analyser);
                    
                    // Create visualizer
                    createVisualizer();
                    
                    // Set up media recorder
                    mediaRecorder = new MediaRecorder(stream);
                    audioChunks = [];
                    
                    // Handle data available event
                    mediaRecorder.ondataavailable = function(event) {
                        audioChunks.push(event.data);
                    };
                    
                    // Handle recording stop
                    mediaRecorder.onstop = async function() {
                        // Clear timer and visualizer
                        clearInterval(timerInterval);
                        
                        // Create audio blob
                        const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                        
                        // Stop all tracks
                        stream.getTracks().forEach(track => track.stop());
                        
                        // Update UI
                        status.textContent = 'Processing audio...';
                        loadingContainer.style.display = 'block';
                        
                        try {
                            // Process audio with make.com (which will use Whisper)
                            await processAudio(audioBlob);
                        } catch (error) {
                            console.error('Error processing audio:', error);
                            status.textContent = 'Error processing audio';
                            status.classList.add('error');
                            loadingContainer.style.display = 'none';
                        }
                    };
                    
                    // Start recording
                    mediaRecorder.start(1000); // Collect data every second
                    
                    // Set up visualizer update
                    const dataArray = new Uint8Array(analyser.frequencyBinCount);
                    
                    const updateVisualizerLoop = () => {
                        if (mediaRecorder && mediaRecorder.state === 'recording') {
                            analyser.getByteFrequencyData(dataArray);
                            updateVisualizer(dataArray);
                            requestAnimationFrame(updateVisualizerLoop);
                        }
                    };
                    
                    updateVisualizerLoop();
                    
                    // Start timer
                    recordingStartTime = Date.now();
                    timerInterval = setInterval(updateTimer, 1000);
                    
                    // Update UI
                    status.innerHTML = '<span class="record-dot"></span> Recording...';
                    status.classList.add('recording');
                    startButton.disabled = true;
                    stopButton.disabled = false;
                    output.textContent = '';
                    aiOutput.textContent = '';
                    
                } catch (err) {
                    console.error('Error accessing microphone:', err);
                    status.textContent = 'Error: Could not access microphone. ' + err.message;
                    status.classList.add('error');
                }
            });
            
            // Stop recording
            stopButton.addEventListener('click', function() {
                if (mediaRecorder && mediaRecorder.state === 'recording') {
                    mediaRecorder.stop();
                    status.textContent = 'Recording stopped';
                    status.classList.remove('recording');
                    startButton.disabled = false;
                    stopButton.disabled = true;
                }
            });
            
            // Clear all
            resetButton.addEventListener('click', function() {
                output.textContent = '';
                aiOutput.textContent = '';
                manualInput.value = '';
                status.textContent = 'Text cleared';
                setTimeout(() => {
                    status.textContent = 'Ready to record';
                }, 1500);
            });
            
            // Toggle mode
            toggleModeButton.addEventListener('click', function() {
                isManualMode = !isManualMode;
                
                if (isManualMode) {
                    startButton.disabled = true;
                    stopButton.disabled = true;
                    manualInput.style.display = 'block';
                    audioVisualizer.style.display = 'none';
                    audioTimer.style.display = 'none';
                    recordingInfo.textContent = 'Type your text in the box below and click "Process with ChatGPT"';
                    toggleModeButton.textContent = 'Switch to Voice Recording';
                    status.textContent = 'Manual input mode';
                } else {
                    startButton.disabled = false;
                    manualInput.style.display = 'none';
                    audioVisualizer.style.display = 'block';
                    audioTimer.style.display = 'block';
                    recordingInfo.textContent = 'Click "Start Recording" and speak into your microphone. ChatGPT will transcribe and respond to your speech.';
                    toggleModeButton.textContent = 'Switch to Manual Input';
                    status.textContent = 'Ready to record';
                }
            });
            
            // Process button
            processButton.addEventListener('click', async function() {
                let text;
                
                if (isManualMode) {
                    // Get text from manual input
                    text = manualInput.value.trim();
                } else {
                    // Get text from speech output
                    text = output.textContent.trim();
                }
                
                if (!text) {
                    status.textContent = 'Please record or type some text first';
                    status.classList.add('error');
                    setTimeout(() => {
                        status.textContent = isManualMode ? 'Manual input mode' : 'Ready to record';
                        status.classList.remove('error');
                    }, 2000);
                    return;
                }
                
                // Show loading indicator
                loadingContainer.style.display = 'block';
                status.textContent = 'Sending to ChatGPT...';
                
                try {
                    // Send text to make.com for ChatGPT processing
                    const response = await sendToChatGPT(text);
                    
                    // Display AI response
                    aiOutput.textContent = response;
                    status.textContent = 'ChatGPT response received';
                } catch (error) {
                    console.error('Error processing with ChatGPT:', error);
                    status.textContent = 'Error: Could not process with ChatGPT';
                    status.classList.add('error');
                    aiOutput.textContent = 'An error occurred while processing your request. Please try again.';
                } finally {
                    // Hide loading indicator
                    loadingContainer.style.display = 'none';
                    setTimeout(() => {
                        status.textContent = isManualMode ? 'Manual input mode' : 'Ready to record';
                        status.classList.remove('error');
                    }, 2000);
                }
            });
            
            // Process audio with Whisper via make.com
            async function processAudio(audioBlob) {
                // Replace this URL with your actual make.com webhook URL
                const makeWebhookUrl = 'https://hook.us2.make.com/pj83qpi1fbz2eo7jhe0x3c317b8vuhta';
                
                try {
                    // Create form data with audio file
                    const formData = new FormData();
                    formData.append('audio', audioBlob, 'recording.webm');
                    
                    // Send to make.com
                    const response = await fetch(makeWebhookUrl, {
                        method: 'POST',
                        body: formData
                    });
                    
                    // Check response
                    if (!response.ok) {
                        throw new Error(`HTTP error! Status: ${response.status}`);
                    }
                    
                    // Parse response
                    const data = await response.json();
                    console.log('Whisper response:', data);
                    
                    // Update output with transcribed text
                    output.textContent = data.transcription || 'No transcription received';
                    status.textContent = 'Audio processed successfully';
                    loadingContainer.style.display = 'none';
                    
                    // Process with ChatGPT automatically if we got a transcription
                    if (data.transcription) {
                        setTimeout(() => {
                            processButton.click();
                        }, 500);
                    }
                    
                } catch (error) {
                    console.error('Error processing audio with Whisper:', error);
                    status.textContent = 'Error processing audio';
                    status.classList.add('error');
                    loadingContainer.style.display = 'none';
                    throw error;
                }
            }
            
            // Send text to ChatGPT
            async function sendToChatGPT(text) {
                // Replace this URL with your actual make.com webhook URL for ChatGPT
                const chatGptWebhookUrl = 'https://hook.eu1.make.com/YOUR_WEBHOOK_ID';
                
                try {
                    console.log('Sending to ChatGPT:', text);
                    
                    const response = await fetch(chatGptWebhookUrl, {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                        },
                        body: JSON.stringify({ text }),
                    });
                    
                    if (!response.ok) {
                        throw new Error(`HTTP error! Status: ${response.status}`);
                    }
                    
                    const data = await response.json();
                    console.log('ChatGPT response:', data);
                    
                    return data.aiResponse || 'No response received';
                    
                } catch (error) {
                    console.error('Error sending to ChatGPT:', error);
                    throw error;
                }
            }
        });
    </script>
</body>
</html>
