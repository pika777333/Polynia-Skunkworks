<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio to Text with ChatGPT</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
            color: #333;
        }
        .container {
            background-color: #f9f9f9;
            border-radius: 10px;
            padding: 20px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }
        h1 {
            text-align: center;
            color: #2c3e50;
        }
        .status {
            text-align: center;
            font-weight: bold;
            margin: 15px 0;
            min-height: 24px;
        }
        .recording {
            color: #e74c3c;
        }
        .controls {
            display: flex;
            justify-content: center;
            flex-wrap: wrap;
            gap: 15px;
            margin-bottom: 20px;
        }
        button {
            background-color: #3498db;
            color: white;
            border: none;
            padding: 10px 20px;
            border-radius: 5px;
            cursor: pointer;
            font-size: 16px;
            transition: background-color 0.3s;
            -webkit-appearance: none;
            -moz-appearance: none;
            appearance: none;
        }
        button:hover {
            background-color: #2980b9;
        }
        button:disabled {
            background-color: #95a5a6;
            cursor: not-allowed;
        }
        #startButton {
            background-color: #2ecc71;
        }
        #startButton:hover {
            background-color: #27ae60;
        }
        #stopButton {
            background-color: #e74c3c;
        }
        #stopButton:hover {
            background-color: #c0392b;
        }
        #resetButton {
            background-color: #95a5a6;
        }
        #resetButton:hover {
            background-color: #7f8c8d;
        }
        .output-container {
            margin-top: 20px;
            display: flex;
            flex-direction: column;
            gap: 20px;
        }
        .output-box {
            width: 100%;
            min-height: 150px;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            font-size: 16px;
            background-color: white;
            overflow-wrap: break-word;
            word-wrap: break-word;
            word-break: break-word;
            box-sizing: border-box;
        }
        .column-header {
            font-weight: bold;
            margin-bottom: 5px;
            color: #2c3e50;
        }
        .error {
            color: #e74c3c;
            text-align: center;
            font-weight: bold;
            margin: 10px 0;
        }
        .info {
            font-size: 14px;
            color: #7f8c8d;
            margin-top: 20px;
            text-align: center;
        }
        .loading {
            text-align: center;
            margin: 10px 0;
        }
        .spinner {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 3px solid rgba(0, 0, 0, 0.1);
            border-radius: 50%;
            border-top-color: #3498db;
            animation: spin 1s ease-in-out infinite;
            margin-right: 10px;
        }
        @keyframes spin {
            to { transform: rotate(360deg); }
        }
        @media (max-width: 600px) {
            .controls {
                flex-direction: column;
                align-items: center;
            }
            button {
                width: 100%;
                max-width: 250px;
            }
        }
        .record-dot {
            display: inline-block;
            width: 12px;
            height: 12px;
            background-color: #e74c3c;
            border-radius: 50%;
            margin-right: 5px;
            animation: pulse 1.5s ease infinite;
        }
        @keyframes pulse {
            0% { transform: scale(0.8); opacity: 0.8; }
            50% { transform: scale(1.2); opacity: 1; }
            100% { transform: scale(0.8); opacity: 0.8; }
        }
        #audioVisualizer {
            width: 100%;
            height: 60px;
            background-color: #f0f0f0;
            border-radius: 5px;
            margin-top: 10px;
            position: relative;
            overflow: hidden;
        }
        .visualizer-bar {
            position: absolute;
            bottom: 0;
            background-color: #3498db;
            width: 3px;
            margin-right: 2px;
            border-radius: 2px 2px 0 0;
        }
        #audioTimer {
            text-align: center;
            font-size: 14px;
            margin-top: 5px;
            color: #7f8c8d;
        }
        #rawResponse {
            margin-top: 20px;
            font-family: monospace;
            font-size: 12px;
            overflow: auto;
            max-height: 200px;
            padding: 10px;
            background-color: #f8f9fa;
            border: 1px solid #ddd;
            border-radius: 5px;
            white-space: pre-wrap;
            display: none;
        }
        #showRawResponseButton {
            background-color: #34495e;
            font-size: 12px;
            padding: 5px 10px;
            margin-top: 5px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Audio to Text with AI</h1>
        <div class="status" id="status">Ready to record</div>
        
        <div class="controls">
            <button id="startButton">Start Recording</button>
            <button id="stopButton" disabled>Stop Recording</button>
            <button id="resetButton">Clear All</button>
        </div>
        
        <div id="audioVisualizer"></div>
        <div id="audioTimer">00:00</div>
        
        <div class="output-container">
            <div>
                <div class="column-header">AI Response:</div>
                <div class="output-box" id="output"></div>
                <div id="loadingContainer" class="loading" style="display: none;">
                    <div class="spinner"></div>
                    <span>Processing audio...</span>
                </div>
            </div>
        </div>
        
        <button id="showRawResponseButton">Show Raw Response</button>
        <div id="rawResponse"></div>
        
        <div class="info">
            <p id="recordingInfo">Click "Start Recording" and speak into your microphone. AI will transcribe and respond to your speech.</p>
            <p id="debugInfo" style="font-size: 12px; color: #999;"></p>
        </div>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const startButton = document.getElementById('startButton');
            const stopButton = document.getElementById('stopButton');
            const resetButton = document.getElementById('resetButton');
            const status = document.getElementById('status');
            const output = document.getElementById('output');
            const loadingContainer = document.getElementById('loadingContainer');
            const audioVisualizer = document.getElementById('audioVisualizer');
            const audioTimer = document.getElementById('audioTimer');
            const showRawResponseButton = document.getElementById('showRawResponseButton');
            const rawResponse = document.getElementById('rawResponse');
            const debugInfo = document.getElementById('debugInfo');
            
            let mediaRecorder;
            let audioChunks = [];
            let recordingStartTime;
            let timerInterval;
            let audioContext;
            let analyser;
            let visualizerBars = [];
            let lastRawResponse = '';
            
            // Debug info
            const isMobile = /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
            debugInfo.textContent = `Device: ${isMobile ? 'Mobile' : 'Desktop'}, Browser: ${navigator.userAgent.includes('Chrome') ? 'Chrome' : 'Other'}`;
            
            // Create visualizer bars
            function createVisualizer() {
                audioVisualizer.innerHTML = '';
                visualizerBars = [];
                
                const barCount = 50;
                const barWidth = audioVisualizer.clientWidth / barCount - 2;
                
                for (let i = 0; i < barCount; i++) {
                    const bar = document.createElement('div');
                    bar.className = 'visualizer-bar';
                    bar.style.left = (i * (barWidth + 2)) + 'px';
                    bar.style.width = barWidth + 'px';
                    bar.style.height = '0px';
                    audioVisualizer.appendChild(bar);
                    visualizerBars.push(bar);
                }
            }
            
            // Update timer display
            function updateTimer() {
                const now = Date.now();
                const elapsedSeconds = Math.floor((now - recordingStartTime) / 1000);
                const minutes = Math.floor(elapsedSeconds / 60).toString().padStart(2, '0');
                const seconds = (elapsedSeconds % 60).toString().padStart(2, '0');
                audioTimer.textContent = `${minutes}:${seconds}`;
            }
            
            // Update visualizer display
            function updateVisualizer(dataArray) {
                for (let i = 0; i < visualizerBars.length; i++) {
                    const value = dataArray[i * Math.floor(dataArray.length / visualizerBars.length)];
                    const height = value / 255 * audioVisualizer.clientHeight;
                    visualizerBars[i].style.height = height + 'px';
                }
            }
            
            // Show/hide raw response
            showRawResponseButton.addEventListener('click', function() {
                if (rawResponse.style.display === 'none' || !rawResponse.style.display) {
                    rawResponse.style.display = 'block';
                    showRawResponseButton.textContent = 'Hide Raw Response';
                } else {
                    rawResponse.style.display = 'none';
                    showRawResponseButton.textContent = 'Show Raw Response';
                }
            });
            
            // Start recording
            startButton.addEventListener('click', async function() {
                try {
                    // Request microphone access
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    
                    // Set up audio context for visualizer
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    const source = audioContext.createMediaStreamSource(stream);
                    analyser = audioContext.createAnalyser();
                    analyser.fftSize = 256;
                    source.connect(analyser);
                    
                    // Create visualizer
                    createVisualizer();
                    
                    // Set up media recorder
                    mediaRecorder = new MediaRecorder(stream);
                    audioChunks = [];
                    
                    // Handle data available event
                    mediaRecorder.ondataavailable = function(event) {
                        audioChunks.push(event.data);
                    };
                    
                    // Handle recording stop
                    mediaRecorder.onstop = async function() {
                        // Clear timer and visualizer
                        clearInterval(timerInterval);
                        
                        // Create audio blob
                        const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                        
                        // Stop all tracks
                        stream.getTracks().forEach(track => track.stop());
                        
                        // Update UI
                        status.textContent = 'Processing audio...';
                        loadingContainer.style.display = 'block';
                        
                        try {
                            // Process audio with make.com
                            await processAudio(audioBlob);
                        } catch (error) {
                            console.error('Error processing audio:', error);
                            status.textContent = 'Error processing audio';
                            status.classList.add('error');
                            loadingContainer.style.display = 'none';
                            
                            // Display error in output
                            output.textContent = 'Error: ' + error.message;
                        }
                    };
                    
                    // Start recording
                    mediaRecorder.start(1000); // Collect data every second
                    
                    // Set up visualizer update
                    const dataArray = new Uint8Array(analyser.frequencyBinCount);
                    
                    const updateVisualizerLoop = () => {
                        if (mediaRecorder && mediaRecorder.state === 'recording') {
                            analyser.getByteFrequencyData(dataArray);
                            updateVisualizer(dataArray);
                            requestAnimationFrame(updateVisualizerLoop);
                        }
                    };
                    
                    updateVisualizerLoop();
                    
                    // Start timer
                    recordingStartTime = Date.now();
                    timerInterval = setInterval(updateTimer, 1000);
                    
                    // Update UI
                    status.innerHTML = '<span class="record-dot"></span> Recording...';
                    status.classList.add('recording');
                    startButton.disabled = true;
                    stopButton.disabled = false;
                    output.textContent = '';
                    
                } catch (err) {
                    console.error('Error accessing microphone:', err);
                    status.textContent = 'Error: Could not access microphone. ' + err.message;
                    status.classList.add('error');
                }
            });
            
            // Stop recording
            stopButton.addEventListener('click', function() {
                if (mediaRecorder && mediaRecorder.state === 'recording') {
                    mediaRecorder.stop();
                    status.textContent = 'Recording stopped';
                    status.classList.remove('recording');
                    startButton.disabled = false;
                    stopButton.disabled = true;
                }
            });
            
            // Clear all
            resetButton.addEventListener('click', function() {
                output.textContent = '';
                rawResponse.textContent = '';
                status.textContent = 'Text cleared';
                setTimeout(() => {
                    status.textContent = 'Ready to record';
                }, 1500);
            });
            
            // Process audio with make.com
            async function processAudio(audioBlob) {
                // Replace this URL with your actual make.com webhook URL
                const makeWebhookUrl = 'https://hook.us2.make.com/pj83qpi1fbz2eo7jhe0x3c317b8vuhta';
                
                try {
                    // Create form data with audio file
                    const formData = new FormData();
                    formData.append('audio', audioBlob, 'recording.webm');
                    
                    // Log the blob size for debugging
                    console.log('Audio blob size:', audioBlob.size, 'bytes');
                    
                    // Send to make.com
                    const response = await fetch(makeWebhookUrl, {
                        method: 'POST',
                        body: formData
                    });
                    
                    // Check response
                    if (!response.ok) {
                        const errorText = await response.text();
                        throw new Error(`HTTP error! Status: ${response.status}, Details: ${errorText}`);
                    }
                    
                    // Get response text first
                    const responseText = await response.text();
                    console.log('Raw response:', responseText);
                    
                    // Store raw response for debugging
                    lastRawResponse = responseText;
                    rawResponse.textContent = responseText;
                    
                    // Try to parse as JSON (if it is JSON)
                    let data;
                    try {
                        data = JSON.parse(responseText);
                        console.log('Parsed response:', data);
                    } catch (e) {
                        console.log('Response is not JSON, using as plain text');
                        data = { text: responseText };
                    }
                    
                    // Display response in a flexible way
                    if (data.transcription) {
                        // If the response has a transcription field
                        output.textContent = data.transcription;
                    } else if (data.text) {
                        // If the response has a text field
                        output.textContent = data.text;
                    } else if (data.aiResponse) {
                        // If the response has an aiResponse field
                        output.textContent = data.aiResponse;
                    } else if (data.result) {
                        // If the response has a result field
                        output.textContent = data.result;
                    } else if (typeof data === 'object') {
                        // If it's an object but doesn't have expected fields, display key values
                        output.textContent = Object.entries(data)
                            .map(([key, value]) => `${key}: ${typeof value === 'object' ? JSON.stringify(value) : value}`)
                            .join('\n');
                    } else {
                        // Fallback to showing the raw response
                        output.textContent = responseText;
                    }
                    
                    // Update UI
                    status.textContent = 'Audio processed successfully';
                    loadingContainer.style.display = 'none';
                    
                } catch (error) {
                    console.error('Error processing audio:', error);
                    rawResponse.textContent = `Error: ${error.message}`;
                    throw error;
                }
            }
        });
    </script>
</body>
</html>
